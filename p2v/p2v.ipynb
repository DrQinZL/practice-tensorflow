{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average loss at step ', 0, ': ', 70.013839721679688)\n",
      "('Average loss at step ', 2000, ': ', 69.458465099334717)\n",
      "('Average loss at step ', 4000, ': ', 68.306635444402701)\n",
      "('Average loss at step ', 6000, ': ', 67.170784470828892)\n",
      "('Average loss at step ', 8000, ': ', 66.036558750389716)\n",
      "('Average loss at step ', 10000, ': ', 64.896763282121782)\n",
      "('Average loss at step ', 12000, ': ', 63.725812629916824)\n",
      "('Average loss at step ', 14000, ': ', 62.4931471661111)\n",
      "('Average loss at step ', 16000, ': ', 61.146574198857714)\n",
      "('Average loss at step ', 18000, ': ', 59.613447392552914)\n",
      "('Average loss at step ', 20000, ': ', 57.801283492189924)\n",
      "('Average loss at step ', 22000, ': ', 55.579718240088987)\n",
      "('Average loss at step ', 24000, ': ', 52.787522387806568)\n",
      "('Average loss at step ', 26000, ': ', 49.27575272611395)\n",
      "('Average loss at step ', 28000, ': ', 45.029972223134294)\n",
      "('Average loss at step ', 30000, ': ', 40.098238086773797)\n",
      "('Average loss at step ', 32000, ': ', 34.770710144090685)\n",
      "('Average loss at step ', 34000, ': ', 29.462013320999169)\n",
      "('Average loss at step ', 36000, ': ', 24.606676589050331)\n",
      "('Average loss at step ', 38000, ': ', 20.478834207778473)\n",
      "('Average loss at step ', 40000, ': ', 17.131507459668281)\n",
      "('Average loss at step ', 42000, ': ', 14.508029224665655)\n",
      "('Average loss at step ', 44000, ': ', 12.466514857412472)\n",
      "('Average loss at step ', 46000, ': ', 10.922013007299007)\n",
      "('Average loss at step ', 48000, ': ', 9.7280444816165659)\n",
      "('Average loss at step ', 50000, ': ', 8.7951014208652278)\n",
      "('Average loss at step ', 52000, ': ', 8.0697001737439553)\n",
      "('Average loss at step ', 54000, ': ', 7.4844199840685768)\n",
      "('Average loss at step ', 56000, ': ', 6.9908746155115198)\n",
      "('Average loss at step ', 58000, ': ', 6.6212251428798847)\n",
      "('Average loss at step ', 60000, ': ', 6.3097002157094106)\n",
      "('Average loss at step ', 62000, ': ', 6.0675264068667349)\n",
      "('Average loss at step ', 64000, ': ', 5.8358077504966772)\n",
      "('Average loss at step ', 66000, ': ', 5.6310770272959632)\n",
      "('Average loss at step ', 68000, ': ', 5.5006810690045231)\n",
      "('Average loss at step ', 70000, ': ', 5.3481741276515065)\n",
      "('Average loss at step ', 72000, ': ', 5.2201477840109236)\n",
      "('Average loss at step ', 74000, ': ', 5.1333409524835423)\n",
      "('Average loss at step ', 76000, ': ', 5.0429556056845621)\n",
      "('Average loss at step ', 78000, ': ', 4.9528159408412868)\n",
      "('Average loss at step ', 80000, ': ', 4.8891889322652728)\n",
      "('Average loss at step ', 82000, ': ', 4.8326162064904405)\n",
      "('Average loss at step ', 84000, ': ', 4.7748128550631224)\n",
      "('Average loss at step ', 86000, ': ', 4.7430189185926013)\n",
      "('Average loss at step ', 88000, ': ', 4.672974715020934)\n",
      "('Average loss at step ', 90000, ': ', 4.6401667211698419)\n",
      "('Average loss at step ', 92000, ': ', 4.5909225175189103)\n",
      "('Average loss at step ', 94000, ': ', 4.5740307870720534)\n",
      "('Average loss at step ', 96000, ': ', 4.5365456113369875)\n",
      "('Average loss at step ', 98000, ': ', 4.5129623907093777)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from model import c2v\n",
    "from data import build_vocab\n",
    "\n",
    "# config\n",
    "config = {\n",
    "    'batch_size'      : 16,\n",
    "    'embed_size'      : 200,\n",
    "    'neg_sample_size' : 100,\n",
    "}\n",
    "\n",
    "# data\n",
    "data, unique_neg_data, idx2word, word2idx, vocab = build_vocab()\n",
    "\n",
    "name2idx = dict([(name, idx) for idx, name in enumerate(data.keys())])\n",
    "idx2name = dict([(idx, name) for idx, name in enumerate(data.keys())])\n",
    "\n",
    "vocab_size = len(idx2word)\n",
    "character_size = len(data)\n",
    "\n",
    "config['vocab_size'] = vocab_size\n",
    "config['character_size'] = character_size\n",
    "\n",
    "# model\n",
    "pos_x, pos_y, neg_y, train, loss, nembed, nearby_character, nearby_val, nearby_idx = c2v(config)\n",
    "\n",
    "# train\n",
    "step_size = 100000\n",
    "learning_rate = 0.025\n",
    "window_size = 5\n",
    "min_count = 5\n",
    "subsample = 1e-3\n",
    "\n",
    "batch_idx = 0\n",
    "data_idx = {}\n",
    "\n",
    "for i in xrange(len(data)):\n",
    "    data_idx[i] = 0\n",
    "\n",
    "def generate_batch(config, data, unique_neg_data):\n",
    "    global batch_idx, data_idx\n",
    "\n",
    "    batch_size = config['batch_size']\n",
    "    neg_sample_size = config['neg_sample_size']\n",
    "\n",
    "    batch = data.values()[batch_idx]\n",
    "    neg_batch = unique_neg_data.values()[batch_idx]\n",
    "    idx = data_idx[batch_idx]\n",
    "\n",
    "    data_pos_x = np.ones(batch_size) * batch_idx\n",
    "    data_pos_y = np.ndarray(shape=batch_size, dtype=np.int32)\n",
    "    data_neg_y = np.ndarray(shape=neg_sample_size, dtype=np.int32)\n",
    "\n",
    "    for i in xrange(batch_size):\n",
    "        data_pos_y[i] = batch[idx]\n",
    "        idx = (idx + 1) % len(batch)\n",
    "\n",
    "    for i, neg_y_idx in enumerate(random.sample(set(neg_batch), neg_sample_size)):\n",
    "        data_neg_y[i] = neg_y_idx\n",
    "\n",
    "    data_idx[batch_idx] = idx\n",
    "    batch_idx = (batch_idx + 1) % len(data)\n",
    "\n",
    "    return data_pos_x, data_pos_y, data_neg_y\n",
    "\n",
    "batch_pkl = \"./batch.pkl\"\n",
    "\n",
    "if os.path.isfile(batch_pkl):\n",
    "    batch = pickle.load(open(batch_pkl))\n",
    "else:\n",
    "    batch = []\n",
    "    for i in xrange(step_size):\n",
    "        batch.append(generate_batch(config, data, unique_neg_data))\n",
    "\n",
    "    pickle.dump(batch, open(batch_pkl, \"wb\"))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "if True:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    average_loss = 0\n",
    "\n",
    "    batch_size = config['batch_size']\n",
    "    neg_sample_size = config['neg_sample_size']\n",
    "\n",
    "    for step in xrange(step_size):\n",
    "        data_pos_x, data_pos_y, data_neg_y = batch[step]\n",
    "        feed_dict = {pos_x: data_pos_x, pos_y: np.reshape(data_pos_y, (batch_size)), neg_y: np.reshape(data_neg_y, (neg_sample_size))}\n",
    "        _, loss_val = sess.run([train, loss], feed_dict=feed_dict)\n",
    "        average_loss += loss_val\n",
    "\n",
    "        if step % 2000 == 0:\n",
    "            if step > 0:\n",
    "                average_loss = average_loss / 2000\n",
    "\n",
    "            print(\"Average loss at step \", step, \": \", average_loss)\n",
    "            acharacter_sizeverage_loss = 0\n",
    "\n",
    "def nearby(words, num=20):\n",
    "    ids = np.array([name2idx.get(x, 0) for x in words])\n",
    "    vals, idx = sess.run(\n",
    "        [nearby_val, nearby_idx], {nearby_character: ids})\n",
    "    for i in xrange(len(words)):\n",
    "        print(words[i])\n",
    "        print()\n",
    "        for (neighbor, distance) in zip(idx[i, :num], vals[i, :num]):\n",
    "            print(\"%-20s %6.4f\" % (idx2name[neighbor], distance))\n",
    "\n",
    "def nearby_with_idx(idxs, num=20):\n",
    "    ids = np.array(idxs)\n",
    "    vals, idx = sess.run(\n",
    "        [nearby_val, nearby_idx], {nearby_character: ids})\n",
    "    for i in xrange(len(idxs)):\n",
    "        print(idx2name[idxs[i]])\n",
    "        print()\n",
    "        for (neighbor, distance) in zip(idx[i, :num], vals[i, :num]):\n",
    "            print(\"%-20s %6.4f\" % (idx2name[neighbor], distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embed_size = config.get('embed_size', 200)\n",
    "batch_size = config.get('batch_size', 16)\n",
    "neg_sample_size = config.get('neg_sample_size', 100)\n",
    "\n",
    "nearby_emb = tf.reshape(tf.gather(nembed, nearby_character), [1, embed_size])\n",
    "nearby_dist = tf.matmul(nearby_emb, nembed, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input has 6400 values, which isn't the same as 200\n\t [[Node: Reshape_2 = Reshape[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Gather_1, Reshape_2/shape)]]\nCaused by op u'Reshape_2', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 592, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 403, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 160, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-58d90709812c>\", line 5, in <module>\n    nearby_emb = tf.reshape(tf.gather(nembed, nearby_character), [1, embed_size])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 554, in reshape\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 639, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1757, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1008, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6bb271f6fc7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnearby_dist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mnearby_character\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcharacter_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \"\"\"\n\u001b[1;32m--> 425\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   2772\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2773\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 2774\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    472\u001b[0m         \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         raise errors._make_specific_exception(node_def, op, error_message,\n\u001b[1;32m--> 474\u001b[1;33m                                               e.code)\n\u001b[0m\u001b[0;32m    475\u001b[0m         \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Input has 6400 values, which isn't the same as 200\n\t [[Node: Reshape_2 = Reshape[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Gather_1, Reshape_2/shape)]]\nCaused by op u'Reshape_2', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 592, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 403, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 160, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-58d90709812c>\", line 5, in <module>\n    nearby_emb = tf.reshape(tf.gather(nembed, nearby_character), [1, embed_size])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 554, in reshape\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 639, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1757, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1008, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "nearby_dist.eval({nearby_character: range(character_size)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "\n",
    "def plot_with_labels(low_dim_embs, labels, filename='p2v.png'):\n",
    "    plt.figure(figsize=(18, 18))  #in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i,:]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label,\n",
    "                     xy=(x, y),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "\n",
    "    plt.savefig(filename)\n",
    "\n",
    "plot_only = 500\n",
    "plot_with_labels(tsne.fit_transform(nembed.eval()[:plot_only,:]), data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
